---
layout: post
---

这是工作以来对 Linux 信号的肤浅讨论和思考。

---
### 一、异步信号安全

似乎做 Web 开发的同学里知道这个并不多？

TL;DR

信号作为 Linux 异步通知机制之一，其 **异步** 的特性大家一定有了解。简单说就是两点：

1. 你指定进程发出信号之后，那个进程究竟在什么时候会收到信号，其实是一个迷。（好的我知道自己给自己可以发同步信号）
2. 进程收到信号之后，理论上可能中断任何正在执行的非原子指令、转而运行信号处理器，那么 race condition 风险已经不言而喻了。

如果一个函数在信号处理器中被调用不会导致 race condition，那么称该函数是 **异步信号安全(async-signal-safe)** 的。

具体来讲，我们可能有几种情况会导致信号处理器出现 race condition：

**1\. 信号处理器调用不可重入函数。**

在 SUSv3 中对可重入 (reentrant) 的概念定义是很清晰的：

> whose effect, when called by two or more threads, is guaranteed to be as if the threads each executed the function one after the other in an undefined order, even if the actual execution is interleaved.

比方说一个函数更新全局变量，那它就是不可重入。`malloc` 和 `free` 维护堆区已释放内存块的链表，如果在执行 `malloc` 的时候被同样调用 `malloc` 的信号处理器中断，那么链表就可能被破坏了。

**2\. 信号处理器自己去更新全局变量。**

这是老生常谈的事情了，多线程玩家早就非常熟悉一套。该加锁的加锁，该加条件变量的加条件变量，不多讲。

我们举个具体的例子，`crypt`。

`crypt` 不是可重入的，因为它使用了静态分配的内存来返回数据，如果信号处理器调用了它，那么会覆盖主程序中上一次调用同一函数所返回的数据。

用 Python + ctypes 来做这件事的话会非常清楚：

```c
// handle_sigint.c

#include <unistd.h>
#include <signal.h>
#include <string.h>

static void handler(int sig) {
    crypt("__", "xx");
}

int handle_sigint() {
    struct sigaction sa;
    sigemptyset(&sa.sa_mask);
    sa.sa_flags = 0;
    sa.sa_handler = handler;
    if (sigaction(SIGINT, &sa, NULL) == -1)
        return -1;
    return 0;
}
```

用 C 注册 SIGINT 的处理器，等下解释为什么一定要用 C。

```shell
gcc handle_sigint.c -shared -o handle_sigint.so
```

然后编译为共享库 `handle_sigint.so`。

```python
# reentrant_sig_handler.py

import os
import sys
import crypt
import ctypes

def main():
    _, word, salt = sys.argv

    module = ctypes.cdll.LoadLibrary(os.path.abspath('./handle_sigint.so'))
    module.handle_sigint()
    correct_password = crypt.crypt(word, salt)
    while True:
        assert crypt.crypt(word, salt) == correct_password


if __name__ == '__main__':
    main()
```

最后利用 `ctypes` 大法在 Python 中注册刚才的 SIGINT 处理器，然后运行，按下 `^C`：


```shell
$ python reentrant_sig_handler.py asdf as
^CTraceback (most recent call last):
  File "reentrant_sig_handler.py", line 46, in <module>
    main()
  File "reentrant_sig_handler.py", line 42, in main
    assert crypt.crypt(word1, salt) == correct_password
AssertionError
```

可以看到我们一旦发送 SIGINT 信号给进程，就会立刻因为信号处理器扰乱了 `crypt` 的静态内存导致主程序状态紊乱。

看起来是很可怕的事情，但是我们平时写信号处理器的时候从来没有顾忌任何的函数是否异步信号安全，居然也没出什么事故，这是为什么？

我们再来看一下一个纯 Python 版本的代码：

```python
def main():
    _, word1, word2, salt = sys.argv

    def int_handler(*args, **kws):
        crypt.crypt(word2, salt)

    signal.signal(signal.SIGINT, int_handler)
    correct_password = crypt.crypt(word1, salt)

    while True:
        assert crypt.crypt(word1, salt) == correct_password
```

如上的代码就不会因为信号处理器中断 `crypt` 导致异常。

在文档中 (https://docs.python.org/3.4/library/signal.html#execution-of-python-signal-handlers) 有如下说明：

> A Python signal handler does not get executed inside the low-level (C) signal handler. Instead, the low-level signal handler sets a flag which tells the virtual machine to execute the corresponding Python signal handler at a later point(for example at the next bytecode instruction). 

具体来讲，我们需要知道以下事实：

1. 我们自定义的 sig_handler，最终实际上并没有注册到内核中，而仅仅是[保存在一个静态数组中](https://github.com/python/cpython/blob/d54cfb160c626626394e2f171d3ccfe03309f34e/Modules/signalmodule.c#L472)；真正注册到内核中的相应的信号处理器，其实是一个[标记函数](https://github.com/python/cpython/blob/d54cfb160c626626394e2f171d3ccfe03309f34e/Modules/signalmodule.c#L316)，标记某个信号来过了。
2. 解释器主循环中调用 [Py_MakePendingCalls](https://github.com/python/cpython/blob/3a9ccee0e5dbf7d67f5ab79f6095755969db117c/Python/ceval.c#L950) 从而调用 [PyErr_CheckSignals](https://github.com/python/cpython/blob/3a9ccee0e5dbf7d67f5ab79f6095755969db117c/Python/ceval.c#L394)，才得以顺利调用注册的信号处理器。

然而这不意味着 Python 里的信号处理器就不会打断内核调用了。上述事实只是针对 `用户自定义信号处理器` 而言，但是对于一些重要信号，比如 `SIGINT`，依然直接注册到内核，并且由解释器捕捉 `EINTR`、返回 `KeyboardInterrupt`。

(建议通篇阅读 PEP0475)

(另外 CPython 源码读起来想死，C 语言才是最地道的依赖注入语言，逃)

所以大体上来说，我们只要别在信号处理器中随意操作全局变量就好了，而不必担心 `这个标准库函数是否调用了非异步信号安全的内核 API`。

### 二、Process Attaching

在一家以 ALG 作为核心竞争力的公司进行开发，遇到的最恶心的 BUG 莫过于上线之后算法模型与线下表现不一致。抛开如何在 ALG 开发、工程开发、CI/CD 流程上规避这种不一致先不谈，首先面临的问题是 `如何 DEBUG` 与 `如何复现 BUG`。每当这时候我都恨不得能够钻进那个正在运行的进程里去看 `这个字典到底有没有被热加载更新`、`那个算法模块 API 到底是不是表现正常`。

那么我们应该如何钻进一个正在运行的进程呢？

考虑一个简单的利用信号的实现：

```python
def sigusr1_handler(sig, frame):
    import pdb
    pdb.set_trace(frame)


signal.signal(signal.SIGUSR1, sigusr1_handler)
```

这种实现非常无脑，抛开问题不管，先说它带来的好处：

1. SIGUSR1 不会占用其他系统级信号，安全。（更别说 SIGUSR1 是实时信号，同一信号实例能够被多次保序传递，虽然在这个场景并没有什么用）
2. 以 `pdb.set_trace` attach 进程而不是 `code.interact` (https://docs.python.org/3/library/code.html#code.interact) 除了能够让我们立刻探索某些单例之外，还能利用 `break` 动态打断点再 `continue` 到这个断点上看某些生命期短小的变量。

但是它带来的问题也很明显：

1. 如果 attach 的进程是一个 server，而进入信号处理器的时候正好进程在处理一个请求还没发出去，那这个请求将一直不响应，客户端超时，之后结束信号处理器之后再发出去响应可能又会遭遇 Connection Reset；
2. 此时在内核 backlog 里的已经处于 ESTABLISHED 的套接字，由于进程阻塞在信号处理上，这些套接字一直不读不写，上游的 Nginx 判断响应超时之后断开连接，将请求 upstream 给下游服务，听上去就操蛋；
3. 如果是 Python Server 的话，那一层 WSGI 容器的主进程在子 worker 没有心跳之后也会强行发 KILL 信号，你 pdb 正在玩耍中突然就 KILLED 肯定也是不开心；
4. 最最最重要的是，当 server 进程是一个后台进程的时候，你无法 attach 一个后台进程到你当前的 tty 里。用更加专业一点的话说，我们无法 undo `disown` 这个命令。好的我知道有一些奇幻的工具 [reptyr](https://github.com/nelhage/reptyr) 什么的号称可以 `reparent a running program to a new terminal`，但是实际使用的时候会有各种问题。

所以我们考虑别的方法，比如用其他的 IPC 工具发送语句，用信号通知后台进程接受并执行语句然后返回，我们再去接收。这样一来等于是我们手动模拟一套 REPL。

虽然进入我脑海的第一个 IPC 是 Unix Socket，但是冷静下来后我觉得 Named Pipe 是不错的选择。

```python
import os
import sys
import signal
import traceback
from gunicorn.workers.ggevent import GeventWorker

REPL_G = {}
REPL_L = {}


class REPLGeventWorker(GeventWorker):

    def handle_usr1(self, sig, frame):
        super().handle_usr1(sig, frame)
        print('handling usr1')
        sys.stdout.flush()

        pipe = f'/tmp/{os.getpid()}.pipe'
        with open(pipe) as pipe:
            input_data = pipe.read(1024).strip()
            if input_data.startswith('p '):
                input_data = f'print({input_data[2:]})'

            print(f'will execute `{input_data}`')
            try:
                exec(input_data, REPL_G, REPL_L)
            except:
                traceback.print_exc()
            sys.stdout.flush()
```

这里 `GeventWorker` 开刀了，直接硬编码从 `/tmp/$pid.pipe` 读输入、运行。`s/^p (.+)/print(\1)/` 是为了省略烦人的 print，从而采用了与 pdb command 一样的 abbr convention。

客户端就简单往这个 pipe 塞语句就行了：

```shell
pid=$1
pipe=/tmp/$pid.pipe
mkfifo $pipe
while read statement; do 
    echo $statement > $pipe &
    kill -s usr1 $pid
done
```

然后随便写一个 hello world 的 Flask app，运行起来：

```shell
gunicorn -c gunicorn.conf.py app:app -k repl_gevent_worker.REPLGeventWorker
```

最后找到想要检查的 worker pid，调用上面的脚本就行了：

```shell
./gunicorn_worker_repl.sh $pid
```

大致思路就是这样没错了。内存泄露什么的细节就先不管了。

然而有个问题是，如果我们执行的语句是一句 CPU 密集语句，可能会导致被信号处理器中断的请求无法及时响应。我们最好禁止还在处理请求时被信号处理器中断。

在同步语义下，我们可以很简单地在请求处理时屏蔽相关信号的传递：

```python
import signal
from gunicorn.workers.sync import SyncWorker


class REPLSyncWorker(SyncWorker):
    def handle(self, *args, **kws):
        signal.pthread_sigmask(signal.SIG_BLOCK, [signal.SIGUSR1])
        super().handle(*args, **kws)
        signal.pthread_sigmask(signal.SIG_UNBLOCK, [signal.SIGUSR1])

    def handle_usr1(self, sig, frame):
        super().handle_usr1(sig, frame)
        print('handling usr1')
```

感谢 Python3.3+ 提供了标准库级别的 API 让我能够运行 `sigprocmask(3)`，否则我只能用 ctypes 表演杂技了。

可以很简单地进行测试，只要在 Flask App 里处理请求的时候睡十秒，然后在此时发送 SIGUSR1，可以确认确实是在响应返回了之后才运行信号处理器，这样我们不用担心如果信号处理器中运行 CPU 密集运算影响还未响应的请求。

但是也仅仅是对于 `SyncWorker` 这种简单线性的 Worker 我们能够这么做。这种做法不仅有问题，而且不可迁移到 coroutine-based worker：

1. 运行信号处理器期间，server socket 依然是监听端口，内核依然在处理三次握手，长时间阻塞会导致 backlog 塞满，同时上游大量 timeout；
2. 对于 GeventWorker 来说，一个请求处理完毕并不代表此时没有其他请求正在处理。

我们将在 `Graceful Termination` 这一节再来讨论这个问题。

不过再次强调，在高负载下的服务上

### 三、Graceful Termination

熟悉 Docker 的朋友都知道，当我们试图停止一个容器的时候，(不是 `docker rm -f`，你们这些变态)，Docker Daemon 实际上先发送 SIGTERM 给容器内一号进程，等待一段时间后若还没有退出，再发送 SIGKILL 一击必杀。

所以 SIGTERM 被作为一个能够让我们优雅处理后事再退出进程的信号，它的信号处理器应该精心设计，否则正在处理一个请求就直接退出进程了，`RemoteDisconnected` 了解一下。

**1\. Worker**

先考虑一个简单的应用，它做两件事：从队列读取一个 URL，然后去 `curl -XGET` 它。

```python
import requests


def worker(msg: dict):
    print(f'received {msg} and handling..')
    try:
        requests.get(msg['url'], timeout=5)
    except (requests.exceptions.ConnectTimeout,
            requests.exceptions.ConnectionError):
        print('f-king GFW')
    else:
        print('done')
```

我们也需要一个简单的会被 IO Block 随机一段时间的 Producer，随手写一个：

```python
import random
import requests
from contextlib import suppress


class MockMQ:
    URL_MUST_TIMEOUT = 'http://www.google.com:81/'

    def recv(self):
        self.io_block(random.random())
        return {'url': self.URL_MUST_TIMEOUT}

    def io_block(self, second: float):
        with suppress(requests.exceptions.ConnectTimeout,
                      requests.exceptions.ConnectionError):
            requests.get(self.URL_MUST_TIMEOUT, timeout=second)


mq = MockMQ()


def feeder():
    return mq.recv()
```

钟爱 `http://www.google.com:81/` 是因为防火墙会 DROP TCP 包，所以就算没有 GFW 也一定会 ConnectionTimeout。

显而易见，这时候优雅退出进程应该是，我们先停止 feeder 生产消息、再等待 worker 完成正在处理的消息、最后再结束进程。

一个简单做法是用全局变量 `alive` 什么的控制主循环，SIGTERM 信号处理器关掉 `alive` 就可以停止。

```python
import sys
import signal
import importlib
from typing import Callable, TypeVar

Msg = TypeVar('Msg')


class SyncDaemon:
    def __init__(self, feeder: Callable[[], Msg],
                 worker: Callable[[Msg], None]):
        self.install_signal_handlers()
        self.feeder = feeder
        self.worker = worker
        self.alive = False

    def run(self):
        self.alive = True
        while self.alive:
            self.worker(self.feeder())
        print('exiting')

    def install_signal_handlers(self):
        signal.signal(signal.SIGINT, self.handle_term)

    def handle_term(self, sig, frame):
        print('recv SIGTERM')
        self.alive = False
```

偷懒使用 `SIGINT` 代替 `SIGTERM`，方便我发信号。

测试一下，非常理想：

```shell
$ python daemon.py feeder.feeder worker.worker sync
received {'url': 'http://www.google.com:81/'} and handling..
^Crecv SIGTERM
^Crecv SIGTERM
^Crecv SIGTERM
f-king GFW
exiting
```

可以看到我按下三次 `^C` 并没有导致进程立刻停止，而是等待 worker 完毕之后再停止。

如果是多线程的话，会更加有趣一些。

```python
class ThreadDaemon(SyncDaemon):
    def __init__(self, feeder, worker, max_thread_num=2):
        super().__init__(feeder, worker)
        self.max_thread_num = max_thread_num
        self.queue = Queue()

    def run(self):
        producer = Thread(target=self.produce)
        producer.start()

        consumers = []
        for _ in range(self.max_thread_num):
            consumer = Thread(target=self.consume, daemon=True)
            consumer.start()
            consumers.append(consumer)

        producer.join()
        print('exiting, waiting for all jobs done')
        self.queue.join()
        print('exit')

    def produce(self):
        self.alive = True
        while self.alive:
            msg = self.feeder()
            print(f'feeding msg {msg}')
            self.queue.put(msg)

    def consume(self):
        while True:
            msg = self.queue.get()
            print(f'got msg {msg}')
            self.worker(msg)
            self.queue.task_done()
```

我们用标准库中的线程安全队列省了不少事情。测试一下：

```shell
$ python daemon.py feeder.feeder worker.worker thread
feeding msg {'url': 'http://www.google.com:81/'}
got msg {'url': 'http://www.google.com:81/'}
received {'url': 'http://www.google.com:81/'} and handling..
feeding msg {'url': 'http://www.google.com:81/'}
got msg {'url': 'http://www.google.com:81/'}
received {'url': 'http://www.google.com:81/'} and handling..
feeding msg {'url': 'http://www.google.com:81/'}
feeding msg {'url': 'http://www.google.com:81/'}
feeding msg {'url': 'http://www.google.com:81/'}
feeding msg {'url': 'http://www.google.com:81/'}
^Crecv SIGTERM
feeding msg {'url': 'http://www.google.com:81/'}
exiting, waiting for all jobs done


f-king GFW
got msg {'url': 'http://www.google.com:81/'}
received {'url': 'http://www.google.com:81/'} and handling..
f-king GFW
got msg {'url': 'http://www.google.com:81/'}
received {'url': 'http://www.google.com:81/'} and handling..
f-king GFW
got msg {'url': 'http://www.google.com:81/'}
received {'url': 'http://www.google.com:81/'} and handling..
f-king GFW
got msg {'url': 'http://www.google.com:81/'}
received {'url': 'http://www.google.com:81/'} and handling..
f-king GFW
got msg {'url': 'http://www.google.com:81/'}
received {'url': 'http://www.google.com:81/'} and handling..
f-king GFW
f-king GFW
exit
```

可以注意到我们按下 `^C` 之后，producer 停止了从队列取消息，进程等待队列中的消息被全部消费之后才退出。

最后再实现一下用 Gevent：

```python
class GeventDaemon(SyncDaemon):
    def __init__(self, feeder, worker):
        super().__init__(feeder, worker)
        self.greenlets = set()

    def run(self):
        self.alive = True
        while self.alive:
            msg = self.feeder()
            greenlet = gevent.spawn(self.worker, msg)
            greenlet.link(self.on_completion)
            self.greenlets.add(greenlet)

        print('exiting, waiting for all greenlets done')
        while len(self.greenlets):
            time.sleep(1)

        print('exit')

    def on_completion(self, greenlet):
        self.greenlets.remove(greenlet)
```

由于我懒得翻文档，就简单搞了一个 greenlet pool 保存正在运行的 greenlet。

```shell
$ python daemon.py feeder.feeder worker.worker gevent
received {'url': 'http://www.google.com:81/'} and handling..
received {'url': 'http://www.google.com:81/'} and handling..
received {'url': 'http://www.google.com:81/'} and handling..
received {'url': 'http://www.google.com:81/'} and handling..
^Crecv SIGTERM
exiting, waiting for all greenlets done
received {'url': 'http://www.google.com:81/'} and handling..
f-king GFW
f-king GFW
f-king GFW
f-king GFW
^Crecv SIGTERM
f-king GFW
exit
```
**2\. WSGI Server**

如果把 WSGI Server 理解成为 `从内核 backlog 队列中取 tcp package，解析之后扔给 WSGI 应用`，那么我们上面的抽象是完全是 Gunicorn 这类 Web Server 的超集。

比方说我们让 feeder 去从从内核 backlog accept 连接：

```python
def feeder(server_sock):
    conn, addr = server_sock.accept()
    return {'peer_sock': conn, 'addr': addr}
```

然后让 worker 去调用具体的 WSGI App：

```python
import os
from app import wsgi


def worker(msg):
    def start_response(status, headers):
        reason = 'OK' if status == 200 else 'UNKNOWN'
        peer_sock.write(f'HTTP/1.1 {status} {reason}\n'.encode())
        for header, content in headers:
            peer_sock.write(f'{header}: {content}\n'.encode())
        peer_sock.write(b'\n')

    peer_sock = msg['peer_sock']
    resp = wsgi(os.environ, start_response)
    peer_sock.send(''.join(resp).encode())
```

好的，这已经是一个~~基本可用的 Gunicorn。~~

（我省略了一些细节，比如现在必须在 Daemon 类中去 `bind((HOST, PORT))` 再传递给 feeder，都是细节）

但是就 `Graceful Termination` 这个问题来看，这里的实现是有问题的。

与上一个小节有所不同，Server 的实现中，就算 `alive` 设置为 `False`、就算我们不再调用 feeder 去 `accept`，内核依然在背地里进行 TCP 三握手建立连接，内核中的 backlog 依然在增长，而之后退出进程只会导致客户端发请求遭遇无情 RESET。

所以正确的做法，应该设置 `alive=False` 之后，关闭 server 套接字的读半部，让内核不再接受新连接。

核心的问题是因为我们此时的 feeder 运行与否并不能控制内核中的队列关闭与否。

这部分的实现可以参考 Gunicorn 里的 [`ThreadWorker` 实现](https://github.com/benoitc/gunicorn/blob/master/gunicorn/workers/gthread.py#L231) 与 [`GeventWorker` 实现](https://github.com/benoitc/gunicorn/blob/master/gunicorn/workers/ggevent.py#L124)。

考虑到这种情况下，我们恐怕很难像之前的代码一样解耦 feeder 与 worker，feeder 必然会集成进入 Daemon 框架，然后就变成了 Gunicorn。

### 四、HUP

本来还想讨论一下让 `HUP` 信号能够重载(reload)进程的事情，因为这里有个问题是违背了 Docker 单进程容器的规则，我们必然需要让一号进程运行一个进程管理器，它能够处理 `SIGHUB` / `SIGINT` / ...，那么要么我们内存多用 supervisord，要么用轻量级 S6 之类的东西。

但是这样真的好吗？

不想写了，就这样吧。
